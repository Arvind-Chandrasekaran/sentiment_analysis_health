{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "openai.api_key = key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def role_based_knowledge_generation():\n",
    "\n",
    "    prompt = (\n",
    "        \"You are an expert in public health sentiment analysis. Explain what sentiment means \"\n",
    "        \"and list common linguistic cues in vaccine and mask hesitancy discourse (e.g., sarcasm, \"\n",
    "        \"negative adjectives, strong expressions like 'hate' or 'disgust'). Provide examples.\"\n",
    "    )\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.0\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def sentiment_detection(sentence):\n",
    "\n",
    "    prompt = f\"Does the following sentence express a sentiment regarding vaccines or masks? Answer Yes or No.\\nSentence: \\\"{sentence}\\\"\"\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.0\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def sentiment_classification(sentence):\n",
    "\n",
    "    prompt = f\"Classify the sentiment of the following sentence as Positive, Negative, or Neutral:\\n\\\"{sentence}\\\"\"\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.0\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def key_phrase_extraction(sentence):\n",
    "\n",
    "    prompt = f\"Identify the key phrases or words that indicate the sentiment in the sentence \\\"{sentence}\\\" and briefly explain why.\"\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.0\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def sentiment_summary(sentence):\n",
    "\n",
    "    prompt = f\"Generate a concise summary of the sentiment expressed in the sentence \\\"{sentence}\\\"\"\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.0\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def rbic_sentiment_pipeline(sentence):\n",
    "\n",
    "    knowledge = role_based_knowledge_generation()\n",
    "    detection = sentiment_detection(sentence)\n",
    "    key_phrases = key_phrase_extraction(sentence)\n",
    "    classification = sentiment_classification(sentence)\n",
    "    summary = sentiment_summary(sentence)\n",
    "    \n",
    "\n",
    "    label_map = {\n",
    "    \"Positive\": 1,\n",
    "    \"Neutral\": 0,\n",
    "    \"Negative\": -1\n",
    "        }\n",
    "\n",
    "    # Convert classification string to numeric label\n",
    "    numeric_label = label_map.get(classification.strip(), None)    \n",
    "\n",
    "    output = {\n",
    "        \"knowledge_base\": knowledge.strip(),\n",
    "        \"sentiment_detected\": detection.strip(),\n",
    "        \"sentiment_label\": numeric_label,\n",
    "        \"key_phrases\": key_phrases.strip(),\n",
    "        \"summary\": summary.strip()\n",
    "    }\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RBIC sentiment pipeline...\n",
      "Sentiment scores saved to posts_with_sentiment.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"annotated_data_set.csv\")\n",
    "df = df[df['selftext'].notnull()]\n",
    "\n",
    "def get_rbic_prediction(text):\n",
    "    try:\n",
    "        result = rbic_sentiment_pipeline(text)\n",
    "        return result['sentiment_label']  # Only get the numeric label\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {text[:30]}... -> {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"Running RBIC sentiment pipeline...\")\n",
    "df['predicted_label'] = df['selftext'].apply(get_rbic_prediction)\n",
    "\n",
    "# Filter out rows where sentiment extraction failed (null predicted labels)\n",
    "df = df[df['predicted_label'].notnull()]\n",
    "\n",
    "# Save the results to a new CSV file while maintaining original order\n",
    "df.to_csv(\"posts_with_sentiment.csv\", index=False)\n",
    "print(\"Sentiment scores saved to posts_with_sentiment.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.50      0.80      0.62         5\n",
      "     Neutral       0.56      1.00      0.72         9\n",
      "    Positive       0.50      0.08      0.14        12\n",
      "\n",
      "    accuracy                           0.54        26\n",
      "   macro avg       0.52      0.63      0.49        26\n",
      "weighted avg       0.52      0.54      0.43        26\n",
      "\n",
      "\n",
      "Weighted F1 Score: 0.4335\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file with sentiment scores\n",
    "df = pd.read_csv(\"posts_with_sentiment.csv\")\n",
    "\n",
    "# Ensure that manual_label is of integer type\n",
    "df['manual_label'] = df['manual_label'].fillna(0).astype(int)\n",
    "\n",
    "\n",
    "# Print classification report for the three classes (Negative: -1, Neutral: 0, Positive: 1)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(df['manual_label'], df['predicted_label'], labels=[-1, 0, 1], target_names=['Negative', 'Neutral', 'Positive']))\n",
    "\n",
    "# Calculate and print the weighted F1 score\n",
    "f1 = f1_score(df['manual_label'], df['predicted_label'], average='weighted')\n",
    "print(f\"\\nWeighted F1 Score: {f1:.4f}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
